{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from random import randint\n",
    "\n",
    "from imblearn.pipeline import make_pipeline as imb_make_pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN #, BorderlineSMOTE\n",
    "# from imblearn.combine import SMOTEENN, SMOTETomek # Tried these, didn't work well\n",
    "from imblearn.ensemble import BalancedBaggingClassifier, BalancedRandomForestClassifier, EasyEnsembleClassifier, RUSBoostClassifier\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer #, SimpleImputer KNNImputer\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate #, cross_val_score\n",
    "\n",
    "from sklearn.dummy import DummyClassifier #, DummyRegressor\n",
    "from sklearn.linear_model import LogisticRegression #, RidgeClassifier, LinearRegression, MultiTaskLassoCV\n",
    "from sklearn.tree import DecisionTreeClassifier #, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier #, RandomForestRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, roc_auc_score #, classification_report, accuracy_score\n",
    "\n",
    "from joblib import dump\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(\"clean_student_data.csv\")\n",
    "\n",
    "df = pd.read_csv(file_path, index_col=\"STU_ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BYSEX       int64\n",
       "BYRACE      int64\n",
       "BYSTLANG    int64\n",
       "BYPARED     int64\n",
       "BYINCOME    int64\n",
       "BYURBAN     int64\n",
       "BYREGION    int64\n",
       "BYRISKFC    int64\n",
       "BYS34A      int64\n",
       "BYS34B      int64\n",
       "BYWRKHRS    int64\n",
       "BYS42       int64\n",
       "BYS43       int64\n",
       "BYTVVIGM    int64\n",
       "BYS46B      int64\n",
       "BYS44C      int64\n",
       "BYS20E      int64\n",
       "BYS87C      int64\n",
       "BYS20D      int64\n",
       "BYS23C      int64\n",
       "BYS37       int64\n",
       "BYS27I      int64\n",
       "BYS90D      int64\n",
       "BYS38A      int64\n",
       "BYS20J      int64\n",
       "BYS24C      int64\n",
       "BYS24D      int64\n",
       "BYS54I      int64\n",
       "BYS84D      int64\n",
       "BYS84I      int64\n",
       "BYS85A      int64\n",
       "F2HSSTAT    int64\n",
       "F2EVERDO    int64\n",
       "F1RGPP2     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0    7095\n",
      " 1    6994\n",
      "-1     707\n",
      "Name: BYSEX, dtype: int64\n",
      " 1    8058\n",
      " 0    5923\n",
      "-1     815\n",
      "Name: BYRACE, dtype: int64\n",
      " 1    11638\n",
      " 0     2343\n",
      "-1      815\n",
      "Name: BYSTLANG, dtype: int64\n",
      " 1    13207\n",
      " 0      841\n",
      "-1      748\n",
      "Name: BYPARED, dtype: int64\n",
      "1    11760\n",
      "0     3036\n",
      "Name: BYINCOME, dtype: int64\n",
      "0    12115\n",
      "1     2681\n",
      "Name: BYURBAN, dtype: int64\n",
      "3    5364\n",
      "2    3749\n",
      "4    3143\n",
      "1    2540\n",
      "Name: BYREGION, dtype: int64\n",
      " 1    6382\n",
      " 0    4695\n",
      "-1    3719\n",
      "Name: BYRISKFC, dtype: int64\n",
      " 1    11351\n",
      "-1     1310\n",
      " 2     1263\n",
      " 0      872\n",
      "Name: BYS34A, dtype: int64\n",
      " 1    10428\n",
      " 2     2276\n",
      "-1     1197\n",
      " 0      895\n",
      "Name: BYS34B, dtype: int64\n",
      " 0    7396\n",
      " 1    4192\n",
      "-1    3208\n",
      "Name: BYWRKHRS, dtype: int64\n",
      " 1    6367\n",
      " 0    4724\n",
      " 2    2212\n",
      "-1    1493\n",
      "Name: BYS42, dtype: int64\n",
      " 1    9137\n",
      " 0    3692\n",
      "-1    1393\n",
      " 2     574\n",
      "Name: BYS43, dtype: int64\n",
      " 0    7892\n",
      " 1    3590\n",
      "-1    3314\n",
      "Name: BYTVVIGM, dtype: int64\n",
      " 0    10321\n",
      " 1     2600\n",
      "-1     1875\n",
      "Name: BYS46B, dtype: int64\n",
      " 1    8836\n",
      " 2    2669\n",
      "-1    1718\n",
      " 3    1348\n",
      " 4     225\n",
      "Name: BYS44C, dtype: int64\n",
      " 2    8898\n",
      " 1    2037\n",
      " 3    1902\n",
      "-1    1549\n",
      " 4     410\n",
      "Name: BYS20E, dtype: int64\n",
      " 3    5009\n",
      "-1    3999\n",
      " 2    2909\n",
      " 4    2110\n",
      " 1     769\n",
      "Name: BYS87C, dtype: int64\n",
      " 2    7149\n",
      " 3    3292\n",
      " 1    2541\n",
      "-1    1475\n",
      " 4     339\n",
      "Name: BYS20D, dtype: int64\n",
      " 0    6707\n",
      " 1    6644\n",
      "-1    1445\n",
      "Name: BYS23C, dtype: int64\n",
      " 4    7256\n",
      " 3    4816\n",
      " 2    1514\n",
      "-1    1041\n",
      " 1     169\n",
      "Name: BYS37, dtype: int64\n",
      " 1    7182\n",
      " 2    5330\n",
      "-1    1448\n",
      " 3     639\n",
      " 4     197\n",
      "Name: BYS27I, dtype: int64\n",
      " 3    5004\n",
      "-1    4941\n",
      " 2    4308\n",
      " 1     543\n",
      "Name: BYS90D, dtype: int64\n",
      " 1    6941\n",
      " 2    4056\n",
      "-1    1543\n",
      " 4    1286\n",
      " 3     970\n",
      "Name: BYS38A, dtype: int64\n",
      " 3    6339\n",
      " 4    5485\n",
      "-1    1545\n",
      " 2    1082\n",
      " 1     345\n",
      "Name: BYS20J, dtype: int64\n",
      " 2    4876\n",
      " 3    4294\n",
      " 1    2074\n",
      "-1    1559\n",
      " 4    1077\n",
      " 5     916\n",
      "Name: BYS24C, dtype: int64\n",
      " 1    7530\n",
      " 2    4128\n",
      "-1    1476\n",
      " 3    1022\n",
      " 5     350\n",
      " 4     290\n",
      "Name: BYS24D, dtype: int64\n",
      " 1    6056\n",
      " 2    4577\n",
      " 3    2729\n",
      "-1    1434\n",
      "Name: BYS54I, dtype: int64\n",
      " 1    10240\n",
      "-1     2446\n",
      " 0     2110\n",
      "Name: BYS84D, dtype: int64\n",
      " 1    10642\n",
      "-1     2516\n",
      " 0     1638\n",
      "Name: BYS84I, dtype: int64\n",
      " 4    4194\n",
      " 3    3499\n",
      "-1    2828\n",
      " 2    2556\n",
      " 1    1719\n",
      "Name: BYS85A, dtype: int64\n",
      "1    13887\n",
      "0      909\n",
      "Name: F2HSSTAT, dtype: int64\n",
      "0    13286\n",
      "1     1510\n",
      "Name: F2EVERDO, dtype: int64\n",
      "2    6475\n",
      "1    4624\n",
      "3    2659\n",
      "0    1038\n",
      "Name: F1RGPP2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create X and y arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[column for column in df.columns if column not in [\"F2HSSTAT\", \"F2EVERDO\", \"F1RGPP2\"]]]\n",
    "\n",
    "y_graduate = df[\"F2HSSTAT\"]\n",
    "y_dropout = df[\"F2EVERDO\"]\n",
    "y_gpa = df[\"F1RGPP2\"]\n",
    "\n",
    "all_y = {\n",
    "    \"y_graduate\": y_graduate,\n",
    "    \"y_dropout\": y_dropout,\n",
    "    \"y_gpa\": y_gpa\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the pipeline for categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [column for column in df.columns if column not in [\"F2HSSTAT\", \"F2EVERDO\", \"F1RGPP2\"]]\n",
    "categorical_transformer = make_pipeline(\n",
    "    IterativeImputer(estimator=RandomForestClassifier(), missing_values=-1),\n",
    "    OneHotEncoder(drop=\"first\", sparse=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up Train-Test-Split Variables and Imbalanced Learn Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_int = randint(0, 1000000)\n",
    "\n",
    "X_train, X_test, y_graduate_train, y_graduate_test = train_test_split(X, y_graduate, test_size=0.2, random_state=random_int, stratify=y_graduate)\n",
    "X_train, X_test, y_dropout_train, y_dropout_test = train_test_split(X, y_dropout, test_size=0.2, random_state=random_int, stratify=y_dropout)\n",
    "X_train, X_test, y_gpa_train, y_gpa_test = train_test_split(X, y_gpa, test_size=0.2, random_state=random_int, stratify=y_gpa)\n",
    "\n",
    "imb_models = {\n",
    "    \"RandomUnderSampler\": RandomUnderSampler(),\n",
    "    \"RandomOverSampler\": RandomOverSampler(),\n",
    "    \"SMOTE\": SMOTE(),\n",
    "    \"ADASYN\": ADASYN()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to fit and predict models and return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_length = 82\n",
    "\n",
    "def train_and_score_model_tts(clf, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    report = classification_report_imbalanced(y_test, y_pred)\n",
    "    \n",
    "    return report\n",
    "\n",
    "\n",
    "def print_report(model, all_y, X=None):\n",
    "    \n",
    "    for y in all_y:\n",
    "        print(\"=\" * bar_length, \"\\n\", y)\n",
    "        report = train_and_score_model_tts(model, X_train, X_test, eval(y + \"_train\"), eval(y + \"_test\"))\n",
    "        print(report)\n",
    "        \n",
    "        model.fit(X_train, eval(y + \"_train\"))\n",
    "        y_prob = model.predict_proba(X_test)\n",
    "        if y != \"y_gpa\":\n",
    "            y_prob = [prob[1] for prob in y_prob]\n",
    "\n",
    "        weighted_roc_auc_ovr = roc_auc_score(eval(y + \"_test\"), y_prob, multi_class=\"ovr\", average=\"weighted\")\n",
    "        print(\"One-vs-Rest ROC AUC score: {:.6f} (weighted by prevalence)\".format(weighted_roc_auc_ovr))\n",
    "        \n",
    "    print(\"=\" * bar_length)\n",
    "    \n",
    "    \n",
    "def print_imb_report(imb_model, clf, all_y, reporter=print_report, X=None):\n",
    "    print(\"=\" * bar_length)\n",
    "    print(imb_model)\n",
    "    reporter(clf, all_y, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================== \n",
      " y_graduate\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.00      0.00      1.00      0.00      0.00      0.00       182\n",
      "          1       0.94      1.00      0.00      0.97      0.00      0.00      2778\n",
      "\n",
      "avg / total       0.88      0.94      0.06      0.91      0.00      0.00      2960\n",
      "\n",
      "One-vs-Rest ROC AUC score: 0.500000 (weighted by prevalence)\n",
      "================================================================================== \n",
      " y_dropout\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.90      1.00      0.00      0.95      0.00      0.00      2658\n",
      "          1       0.00      0.00      1.00      0.00      0.00      0.00       302\n",
      "\n",
      "avg / total       0.81      0.90      0.10      0.85      0.00      0.00      2960\n",
      "\n",
      "One-vs-Rest ROC AUC score: 0.500000 (weighted by prevalence)\n",
      "================================================================================== \n",
      " y_gpa\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.00      0.00      1.00      0.00      0.00      0.00       208\n",
      "          1       0.00      0.00      1.00      0.00      0.00      0.00       925\n",
      "          2       0.44      1.00      0.00      0.61      0.00      0.00      1295\n",
      "          3       0.00      0.00      1.00      0.00      0.00      0.00       532\n",
      "\n",
      "avg / total       0.19      0.44      0.56      0.27      0.00      0.00      2960\n",
      "\n",
      "One-vs-Rest ROC AUC score: 0.500000 (weighted by prevalence)\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "dc = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    DummyClassifier(strategy=\"prior\")\n",
    ")\n",
    "\n",
    "print_report(dc, all_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict using RandomForestClassifier without imbalanced learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================== \n",
      " y_graduate\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.00      0.00      1.00      0.00      0.00      0.00       182\n",
      "          1       0.94      1.00      0.00      0.97      0.00      0.00      2778\n",
      "\n",
      "avg / total       0.88      0.94      0.06      0.91      0.00      0.00      2960\n",
      "\n",
      "One-vs-Rest ROC AUC score: 0.506183 (weighted by prevalence)\n",
      "================================================================================== \n",
      " y_dropout\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.90      1.00      0.00      0.95      0.06      0.00      2658\n",
      "          1       1.00      0.00      1.00      0.01      0.06      0.00       302\n",
      "\n",
      "avg / total       0.91      0.90      0.11      0.85      0.06      0.00      2960\n",
      "\n",
      "One-vs-Rest ROC AUC score: 0.526134 (weighted by prevalence)\n",
      "================================================================================== \n",
      " y_gpa\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.47      0.04      1.00      0.08      0.21      0.04       208\n",
      "          1       0.53      0.60      0.76      0.56      0.67      0.45       925\n",
      "          2       0.54      0.65      0.57      0.59      0.61      0.38      1295\n",
      "          3       0.59      0.37      0.94      0.46      0.59      0.33       532\n",
      "\n",
      "avg / total       0.54      0.54      0.73      0.52      0.60      0.37      2960\n",
      "\n",
      "One-vs-Rest ROC AUC score: 0.743432 (weighted by prevalence)\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    RandomForestClassifier()\n",
    ")\n",
    "\n",
    "print_report(clf, all_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict using RandomForestClassifier with imbalanced learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================\n",
      "RandomUnderSampler\n",
      "================================================================================== \n",
      " y_graduate\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.06      0.52      0.47      0.11      0.49      0.25       182\n",
      "          1       0.94      0.47      0.52      0.63      0.49      0.24      2778\n",
      "\n",
      "avg / total       0.88      0.47      0.52      0.59      0.49      0.24      2960\n",
      "\n",
      "One-vs-Rest ROC AUC score: 0.510614 (weighted by prevalence)\n",
      "================================================================================== \n",
      " y_dropout\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.90      0.55      0.44      0.68      0.49      0.24      2658\n",
      "          1       0.10      0.44      0.55      0.16      0.49      0.24       302\n",
      "\n",
      "avg / total       0.81      0.54      0.45      0.63      0.49      0.24      2960\n",
      "\n",
      "One-vs-Rest ROC AUC score: 0.505278 (weighted by prevalence)\n",
      "================================================================================== \n",
      " y_gpa\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.18      0.62      0.79      0.28      0.70      0.48       208\n",
      "          1       0.48      0.37      0.82      0.42      0.55      0.29       925\n",
      "          2       0.60      0.31      0.84      0.41      0.51      0.25      1295\n",
      "          3       0.45      0.72      0.80      0.55      0.76      0.58       532\n",
      "\n",
      "avg / total       0.51      0.43      0.82      0.43      0.58      0.34      2960\n",
      "\n",
      "One-vs-Rest ROC AUC score: 0.732021 (weighted by prevalence)\n",
      "==================================================================================\n",
      "==================================================================================\n",
      "RandomOverSampler\n",
      "================================================================================== \n",
      " y_graduate\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.03      0.01      0.97      0.02      0.10      0.01       182\n",
      "          1       0.94      0.97      0.01      0.96      0.10      0.01      2778\n",
      "\n",
      "avg / total       0.88      0.91      0.07      0.90      0.10      0.01      2960\n",
      "\n",
      "One-vs-Rest ROC AUC score: 0.507850 (weighted by prevalence)\n",
      "================================================================================== \n",
      " y_dropout\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.90      0.98      0.03      0.94      0.17      0.03      2658\n",
      "          1       0.14      0.03      0.98      0.05      0.17      0.03       302\n",
      "\n",
      "avg / total       0.82      0.88      0.13      0.85      0.17      0.03      2960\n",
      "\n",
      "One-vs-Rest ROC AUC score: 0.537090 (weighted by prevalence)\n",
      "================================================================================== \n",
      " y_gpa\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.19      0.16      0.95      0.17      0.39      0.14       208\n",
      "          1       0.53      0.63      0.75      0.57      0.68      0.46       925\n",
      "          2       0.58      0.53      0.70      0.55      0.61      0.36      1295\n",
      "          3       0.54      0.52      0.90      0.53      0.68      0.45       532\n",
      "\n",
      "avg / total       0.53      0.53      0.77      0.53      0.63      0.39      2960\n",
      "\n",
      "One-vs-Rest ROC AUC score: 0.740236 (weighted by prevalence)\n",
      "==================================================================================\n",
      "==================================================================================\n",
      "SMOTE\n",
      "================================================================================== \n",
      " y_graduate\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.06      0.01      0.99      0.01      0.07      0.00       182\n",
      "          1       0.94      0.99      0.01      0.97      0.07      0.01      2778\n",
      "\n",
      "avg / total       0.88      0.93      0.07      0.91      0.07      0.01      2960\n",
      "\n",
      "One-vs-Rest ROC AUC score: 0.500536 (weighted by prevalence)\n",
      "================================================================================== \n",
      " y_dropout\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.90      0.98      0.02      0.94      0.14      0.02      2658\n",
      "          1       0.11      0.02      0.98      0.03      0.14      0.02       302\n",
      "\n",
      "avg / total       0.82      0.88      0.12      0.85      0.14      0.02      2960\n",
      "\n",
      "One-vs-Rest ROC AUC score: 0.508210 (weighted by prevalence)\n",
      "================================================================================== \n",
      " y_gpa\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.22      0.19      0.95      0.20      0.42      0.16       208\n",
      "          1       0.54      0.61      0.76      0.57      0.68      0.46       925\n",
      "          2       0.57      0.59      0.65      0.58      0.62      0.38      1295\n",
      "          3       0.59      0.43      0.93      0.50      0.63      0.38       532\n",
      "\n",
      "avg / total       0.54      0.54      0.76      0.54      0.63      0.39      2960\n",
      "\n",
      "One-vs-Rest ROC AUC score: 0.741475 (weighted by prevalence)\n",
      "==================================================================================\n",
      "==================================================================================\n",
      "ADASYN\n",
      "================================================================================== \n",
      " y_graduate\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.04      0.01      0.98      0.02      0.10      0.01       182\n",
      "          1       0.94      0.98      0.01      0.96      0.10      0.01      2778\n",
      "\n",
      "avg / total       0.88      0.92      0.07      0.90      0.10      0.01      2960\n",
      "\n",
      "One-vs-Rest ROC AUC score: 0.498827 (weighted by prevalence)\n",
      "================================================================================== \n",
      " y_dropout\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.90      0.99      0.01      0.94      0.08      0.01      2658\n",
      "          1       0.07      0.01      0.99      0.01      0.08      0.01       302\n",
      "\n",
      "avg / total       0.81      0.89      0.11      0.85      0.08      0.01      2960\n",
      "\n",
      "One-vs-Rest ROC AUC score: 0.508593 (weighted by prevalence)\n",
      "================================================================================== \n",
      " y_gpa\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.19      0.18      0.94      0.19      0.41      0.16       208\n",
      "          1       0.54      0.59      0.77      0.57      0.68      0.45       925\n",
      "          2       0.57      0.59      0.65      0.58      0.62      0.39      1295\n",
      "          3       0.58      0.43      0.93      0.50      0.64      0.38       532\n",
      "\n",
      "avg / total       0.54      0.54      0.76      0.53      0.63      0.39      2960\n",
      "\n",
      "One-vs-Rest ROC AUC score: 0.742986 (weighted by prevalence)\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "for imb_model in imb_models:\n",
    "    \n",
    "    rus_clf = imb_make_pipeline(\n",
    "        StandardScaler(),\n",
    "        imb_models[imb_model],\n",
    "        RandomForestClassifier()\n",
    "    )\n",
    "\n",
    "    print_imb_report(imb_model, rus_clf, all_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict using BalancedRandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================== \n",
      " y_graduate\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.06      0.51      0.49      0.11      0.50      0.25       182\n",
      "          1       0.94      0.49      0.51      0.65      0.50      0.25      2778\n",
      "\n",
      "avg / total       0.88      0.49      0.50      0.61      0.50      0.25      2960\n",
      "\n",
      "One-vs-Rest ROC AUC score: 0.503269 (weighted by prevalence)\n",
      "================================================================================== \n",
      " y_dropout\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.89      0.50      0.48      0.65      0.49      0.24      2658\n",
      "          1       0.10      0.48      0.50      0.16      0.49      0.24       302\n",
      "\n",
      "avg / total       0.81      0.50      0.48      0.60      0.49      0.24      2960\n",
      "\n",
      "One-vs-Rest ROC AUC score: 0.490363 (weighted by prevalence)\n",
      "================================================================================== \n",
      " y_gpa\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.19      0.66      0.78      0.29      0.72      0.51       208\n",
      "          1       0.51      0.41      0.83      0.45      0.58      0.32       925\n",
      "          2       0.65      0.33      0.86      0.43      0.53      0.27      1295\n",
      "          3       0.46      0.73      0.81      0.57      0.77      0.59       532\n",
      "\n",
      "avg / total       0.54      0.45      0.84      0.45      0.60      0.36      2960\n",
      "\n",
      "One-vs-Rest ROC AUC score: 0.748673 (weighted by prevalence)\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "brf = imb_make_pipeline(\n",
    "    StandardScaler(),\n",
    "    BalancedRandomForestClassifier()\n",
    ")\n",
    "\n",
    "print_report(brf, all_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN-TEST-SPLIT RESULTS: No models do very well, and they all yield relatively similar results.\n",
    "### The models do not do well at predicting successful high school graduation or high school dropouts.\n",
    "### However, RandomForestClassifier with RandomOverSampler imbalanced learn appears to do reasonably better than the null model. Therefore, we will select this model for our app.\n",
    "## Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('randomoversampler',\n",
       "                 RandomOverSampler(random_state=None,\n",
       "                                   sampling_strategy='auto')),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=None, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rus_clf = imb_make_pipeline(\n",
    "    StandardScaler(),\n",
    "    imb_models[\"RandomOverSampler\"],\n",
    "    RandomForestClassifier()\n",
    ")\n",
    "\n",
    "rus_clf.fit(X, y_gpa)\n",
    "dump(rus_clf, \"rus_clf.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "### This is mostly to confirm that these models don't do any better then train-test-split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_report(model, all_y, X):\n",
    "    \n",
    "    cv_accuracy_lst = []\n",
    "    cv_precision_lst = []\n",
    "    cv_recall_lst = []\n",
    "        \n",
    "    for y in all_y:\n",
    "        \n",
    "        cv_dict = cross_validate(model, X, all_y[y], scoring={\n",
    "            \"Accuracy\": \"accuracy\",\n",
    "            \"Weighted_Precision\": make_scorer(precision_score, average=\"weighted\", zero_division=0),\n",
    "            \"Weighted_Recall\": make_scorer(recall_score, average=\"weighted\", zero_division=0)\n",
    "        })\n",
    "\n",
    "        cv_accuracy = cv_dict[\"test_Accuracy\"].mean()\n",
    "        cv_accuracy_lst.append(cv_accuracy)\n",
    "        \n",
    "        cv_precision = cv_dict[\"test_Weighted_Precision\"].mean()\n",
    "        cv_precision_lst.append(cv_precision)\n",
    "        \n",
    "        cv_recall = cv_dict[\"test_Weighted_Recall\"].mean()\n",
    "        cv_recall_lst.append(cv_recall)\n",
    "    \n",
    "    return pd.DataFrame(data={\"parameter\": list(all_y.keys()), \"accuracy\": cv_accuracy_lst, \"weighted_precision\": cv_precision_lst, \"weighted_recall\": cv_recall_lst}).set_index(\"parameter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Not Utilizing Imbalanced Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>weighted_precision</th>\n",
       "      <th>weighted_recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parameter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y_graduate</th>\n",
       "      <td>0.938564</td>\n",
       "      <td>0.880903</td>\n",
       "      <td>0.938564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_dropout</th>\n",
       "      <td>0.897945</td>\n",
       "      <td>0.806306</td>\n",
       "      <td>0.897945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_gpa</th>\n",
       "      <td>0.437618</td>\n",
       "      <td>0.191510</td>\n",
       "      <td>0.437618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            accuracy  weighted_precision  weighted_recall\n",
       "parameter                                                \n",
       "y_graduate  0.938564            0.880903         0.938564\n",
       "y_dropout   0.897945            0.806306         0.897945\n",
       "y_gpa       0.437618            0.191510         0.437618"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    DummyClassifier(strategy=\"prior\")\n",
    ")\n",
    "\n",
    "cv_report(dc, all_y, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>weighted_precision</th>\n",
       "      <th>weighted_recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parameter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y_graduate</th>\n",
       "      <td>0.937551</td>\n",
       "      <td>0.913372</td>\n",
       "      <td>0.937551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_dropout</th>\n",
       "      <td>0.895242</td>\n",
       "      <td>0.863801</td>\n",
       "      <td>0.895242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_gpa</th>\n",
       "      <td>0.530345</td>\n",
       "      <td>0.528015</td>\n",
       "      <td>0.530345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            accuracy  weighted_precision  weighted_recall\n",
       "parameter                                                \n",
       "y_graduate  0.937551            0.913372         0.937551\n",
       "y_dropout   0.895242            0.863801         0.895242\n",
       "y_gpa       0.530345            0.528015         0.530345"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "cv_report(lr, all_y, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>weighted_precision</th>\n",
       "      <th>weighted_recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parameter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y_graduate</th>\n",
       "      <td>0.858271</td>\n",
       "      <td>0.895953</td>\n",
       "      <td>0.858271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_dropout</th>\n",
       "      <td>0.798592</td>\n",
       "      <td>0.837173</td>\n",
       "      <td>0.798592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_gpa</th>\n",
       "      <td>0.429440</td>\n",
       "      <td>0.431559</td>\n",
       "      <td>0.429440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            accuracy  weighted_precision  weighted_recall\n",
       "parameter                                                \n",
       "y_graduate  0.858271            0.895953         0.858271\n",
       "y_dropout   0.798592            0.837173         0.798592\n",
       "y_gpa       0.429440            0.431559         0.429440"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    DecisionTreeClassifier()\n",
    ")\n",
    "\n",
    "cv_report(dt, all_y, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>weighted_precision</th>\n",
       "      <th>weighted_recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parameter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y_graduate</th>\n",
       "      <td>0.922140</td>\n",
       "      <td>0.893293</td>\n",
       "      <td>0.922140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_dropout</th>\n",
       "      <td>0.878006</td>\n",
       "      <td>0.848592</td>\n",
       "      <td>0.878006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_gpa</th>\n",
       "      <td>0.529398</td>\n",
       "      <td>0.521803</td>\n",
       "      <td>0.529398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            accuracy  weighted_precision  weighted_recall\n",
       "parameter                                                \n",
       "y_graduate  0.922140            0.893293         0.922140\n",
       "y_dropout   0.878006            0.848592         0.878006\n",
       "y_gpa       0.529398            0.521803         0.529398"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    RandomForestClassifier()\n",
    ")\n",
    "\n",
    "cv_report(rf, all_y, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>weighted_precision</th>\n",
       "      <th>weighted_recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parameter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y_graduate</th>\n",
       "      <td>0.903148</td>\n",
       "      <td>0.899150</td>\n",
       "      <td>0.903148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_dropout</th>\n",
       "      <td>0.848267</td>\n",
       "      <td>0.846133</td>\n",
       "      <td>0.848267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_gpa</th>\n",
       "      <td>0.494930</td>\n",
       "      <td>0.492193</td>\n",
       "      <td>0.494930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            accuracy  weighted_precision  weighted_recall\n",
       "parameter                                                \n",
       "y_graduate  0.903148            0.899150         0.903148\n",
       "y_dropout   0.848267            0.846133         0.848267\n",
       "y_gpa       0.494930            0.492193         0.494930"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    MLPClassifier()\n",
    ")\n",
    "\n",
    "cv_report(mlp, all_y, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Utilizing Imbalanced Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "SMOTE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>weighted_precision</th>\n",
       "      <th>weighted_recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parameter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y_graduate</th>\n",
       "      <td>0.061436</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>0.061436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_dropout</th>\n",
       "      <td>0.897945</td>\n",
       "      <td>0.806306</td>\n",
       "      <td>0.897945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_gpa</th>\n",
       "      <td>0.070154</td>\n",
       "      <td>0.004922</td>\n",
       "      <td>0.070154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            accuracy  weighted_precision  weighted_recall\n",
       "parameter                                                \n",
       "y_graduate  0.061436            0.003774         0.061436\n",
       "y_dropout   0.897945            0.806306         0.897945\n",
       "y_gpa       0.070154            0.004922         0.070154"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc = imb_make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SMOTE(),\n",
    "    DummyClassifier(strategy=\"prior\")\n",
    ")\n",
    "\n",
    "print(\"=\" * 57)\n",
    "print(\"SMOTE\")\n",
    "cv_report(dc, all_y, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================= \n",
      " RandomUnderSampler\n",
      "            accuracy  weighted_precision  weighted_recall\n",
      "parameter                                                \n",
      "y_graduate  0.629828             0.92092         0.629828\n",
      "y_dropout   0.656523             0.87670         0.656523\n",
      "y_gpa       0.409502             0.48568         0.409502\n",
      "========================================================= \n",
      " RandomOverSampler\n",
      "            accuracy  weighted_precision  weighted_recall\n",
      "parameter                                                \n",
      "y_graduate  0.661863            0.919989         0.661863\n",
      "y_dropout   0.661255            0.877401         0.661255\n",
      "y_gpa       0.413760            0.488891         0.413760\n",
      "========================================================= \n",
      " SMOTE\n",
      "            accuracy  weighted_precision  weighted_recall\n",
      "parameter                                                \n",
      "y_graduate  0.653616            0.920350         0.653616\n",
      "y_dropout   0.662065            0.876889         0.662065\n",
      "y_gpa       0.416125            0.487007         0.416125\n",
      "========================================================= \n",
      " ADASYN\n",
      "            accuracy  weighted_precision  weighted_recall\n",
      "parameter                                                \n",
      "y_graduate  0.644694            0.920171         0.644694\n",
      "y_dropout   0.659428            0.877897         0.659428\n",
      "y_gpa       0.407136            0.486863         0.407136\n"
     ]
    }
   ],
   "source": [
    "for imb_model in imb_models:\n",
    "    \n",
    "    lr = imb_make_pipeline(\n",
    "        StandardScaler(),\n",
    "        imb_models[imb_model],\n",
    "        LogisticRegression()\n",
    "    )\n",
    "\n",
    "    print(\"=\" * 57, \"\\n\", imb_model)\n",
    "    print(cv_report(lr, all_y, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================= \n",
      " RandomUnderSampler\n",
      "            accuracy  weighted_precision  weighted_recall\n",
      "parameter                                                \n",
      "y_graduate  0.604485            0.904072         0.604485\n",
      "y_dropout   0.597658            0.849969         0.597658\n",
      "y_gpa       0.370641            0.430456         0.370641\n",
      "========================================================= \n",
      " RandomOverSampler\n",
      "            accuracy  weighted_precision  weighted_recall\n",
      "parameter                                                \n",
      "y_graduate  0.839616            0.893207         0.839616\n",
      "y_dropout   0.787979            0.834319         0.787979\n",
      "y_gpa       0.423019            0.435638         0.423019\n",
      "========================================================= \n",
      " SMOTE\n",
      "            accuracy  weighted_precision  weighted_recall\n",
      "parameter                                                \n",
      "y_graduate  0.838198            0.893676         0.838198\n",
      "y_dropout   0.773855            0.833994         0.773855\n",
      "y_gpa       0.417950            0.428296         0.417950\n",
      "========================================================= \n",
      " ADASYN\n",
      "            accuracy  weighted_precision  weighted_recall\n",
      "parameter                                                \n",
      "y_graduate  0.843808            0.892917         0.843808\n",
      "y_dropout   0.786967            0.835245         0.786967\n",
      "y_gpa       0.414030            0.425641         0.414030\n"
     ]
    }
   ],
   "source": [
    "for imb_model in imb_models:\n",
    "    \n",
    "    dt = imb_make_pipeline(\n",
    "        StandardScaler(),\n",
    "        imb_models[imb_model],\n",
    "        DecisionTreeClassifier()\n",
    "    )\n",
    "\n",
    "    print(\"=\" * 57, \"\\n\", imb_model)\n",
    "    print(cv_report(dt, all_y, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================= \n",
      " RandomUnderSampler\n",
      "            accuracy  weighted_precision  weighted_recall\n",
      "parameter                                                \n",
      "y_graduate  0.641316            0.922192         0.641316\n",
      "y_dropout   0.650777            0.875937         0.650777\n",
      "y_gpa       0.422545            0.491187         0.422545\n",
      "========================================================= \n",
      " RandomOverSampler\n",
      "            accuracy  weighted_precision  weighted_recall\n",
      "parameter                                                \n",
      "y_graduate  0.889292            0.890071         0.889292\n",
      "y_dropout   0.850091            0.837082         0.850091\n",
      "y_gpa       0.514799            0.512483         0.514799\n",
      "========================================================= \n",
      " SMOTE\n",
      "            accuracy  weighted_precision  weighted_recall\n",
      "parameter                                                \n",
      "y_graduate  0.908623            0.887883         0.908623\n",
      "y_dropout   0.854756            0.830864         0.854756\n",
      "y_gpa       0.515543            0.511436         0.515543\n",
      "========================================================= \n",
      " ADASYN\n",
      "            accuracy  weighted_precision  weighted_recall\n",
      "parameter                                                \n",
      "y_graduate  0.908623            0.887311         0.908623\n",
      "y_dropout   0.864015            0.830530         0.864015\n",
      "y_gpa       0.513381            0.505732         0.513381\n"
     ]
    }
   ],
   "source": [
    "for imb_model in imb_models:\n",
    "    \n",
    "    rf = imb_make_pipeline(\n",
    "        StandardScaler(),\n",
    "        imb_models[imb_model],\n",
    "        RandomForestClassifier()\n",
    "    )\n",
    "\n",
    "    print(\"=\" * 57, \"\\n\", imb_model)\n",
    "    print(cv_report(rf, all_y, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            accuracy  weighted_precision  weighted_recall\n",
      "parameter                                                \n",
      "y_graduate  0.665513            0.917057         0.665513\n",
      "y_dropout   0.731882            0.858087         0.731882\n",
      "y_gpa       0.421667            0.473842         0.421667\n"
     ]
    }
   ],
   "source": [
    "rf = imb_make_pipeline(\n",
    "    StandardScaler(),\n",
    "    BalancedBaggingClassifier()\n",
    ")\n",
    "\n",
    "print(cv_report(rf, all_y, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            accuracy  weighted_precision  weighted_recall\n",
      "parameter                                                \n",
      "y_graduate  0.650711            0.923709         0.650711\n",
      "y_dropout   0.648614            0.879325         0.648614\n",
      "y_gpa       0.426128            0.513193         0.426128\n"
     ]
    }
   ],
   "source": [
    "brf = imb_make_pipeline(\n",
    "    StandardScaler(),\n",
    "    BalancedRandomForestClassifier()\n",
    ")\n",
    "\n",
    "print(cv_report(brf, all_y, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy Ensemble Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            accuracy  weighted_precision  weighted_recall\n",
      "parameter                                                \n",
      "y_graduate  0.638479            0.925238         0.638479\n",
      "y_dropout   0.643678            0.878618         0.643678\n",
      "y_gpa       0.422951            0.505593         0.422951\n"
     ]
    }
   ],
   "source": [
    "ee = imb_make_pipeline(\n",
    "    StandardScaler(),\n",
    "    EasyEnsembleClassifier()\n",
    ")\n",
    "\n",
    "print(cv_report(ee, all_y, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUS Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            accuracy  weighted_precision  weighted_recall\n",
      "parameter                                                \n",
      "y_graduate  0.631720            0.923010         0.631720\n",
      "y_dropout   0.635095            0.876139         0.635095\n",
      "y_gpa       0.410651            0.487840         0.410651\n"
     ]
    }
   ],
   "source": [
    "rusb = imb_make_pipeline(\n",
    "    StandardScaler(),\n",
    "    RUSBoostClassifier()\n",
    ")\n",
    "\n",
    "print(cv_report(rusb, all_y, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer Perceptron Classifier with Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================= \n",
      " RandomUnderSampler\n",
      "            accuracy  weighted_precision  weighted_recall\n",
      "parameter                                                \n",
      "y_graduate  0.626653            0.915761         0.626653\n",
      "y_dropout   0.631785            0.867463         0.631785\n",
      "y_gpa       0.410110            0.469621         0.410110\n",
      "========================================================= \n",
      " RandomOverSampler\n",
      "            accuracy  weighted_precision  weighted_recall\n",
      "parameter                                                \n",
      "y_graduate  0.830490            0.895551         0.830490\n",
      "y_dropout   0.760404            0.844539         0.760404\n",
      "y_gpa       0.452351            0.490339         0.452351\n",
      "========================================================= \n",
      " SMOTE\n",
      "            accuracy  weighted_precision  weighted_recall\n",
      "parameter                                                \n",
      "y_graduate  0.847320            0.895315         0.847320\n",
      "y_dropout   0.781963            0.841450         0.781963\n",
      "y_gpa       0.451608            0.482103         0.451608\n",
      "========================================================= \n",
      " ADASYN\n",
      "            accuracy  weighted_precision  weighted_recall\n",
      "parameter                                                \n",
      "y_graduate  0.839547            0.896014         0.839547\n",
      "y_dropout   0.786019            0.839412         0.786019\n",
      "y_gpa       0.457150            0.481845         0.457150\n"
     ]
    }
   ],
   "source": [
    "for imb_model in imb_models:\n",
    "\n",
    "    mlp = imb_make_pipeline(\n",
    "        StandardScaler(),\n",
    "        imb_models[imb_model],\n",
    "        MLPClassifier()\n",
    "    )\n",
    "\n",
    "    print(\"=\" * 57, \"\\n\", imb_model)\n",
    "    print(cv_report(mlp, all_y, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CROSS VALIDATION RESULTS: No models do very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-3",
   "language": "python",
   "name": "project-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
